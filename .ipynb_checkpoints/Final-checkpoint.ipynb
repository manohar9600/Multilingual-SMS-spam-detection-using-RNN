{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:45:39.288674Z",
     "start_time": "2018-05-23T05:44:42.822974Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:45:40.385689Z",
     "start_time": "2018-05-23T05:45:39.290669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle dataset head:\n",
      "Our dataset head:\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('Resources/spam.csv', encoding = 'latin-1') # Kaggle dataset\n",
    "data1 = data1.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
    "print(\"Kaggle dataset head:\")\n",
    "data1.head()\n",
    "\n",
    "data2 = pd.ExcelFile('Resources/revisedindiandataset.xls')\n",
    "data2 = data2.parse(0)\n",
    "data2 = data2.drop(['code'], axis = 1)\n",
    "print(\"Our dataset head:\")\n",
    "data2.head()\n",
    "\n",
    "data = pd.concat([data1, data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:45:40.460489Z",
     "start_time": "2018-05-23T05:45:40.387685Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class userfunc:\n",
    "\n",
    "    def fit_texts(self, data, num_words):\n",
    "        temp = []\n",
    "        for row in data.itertuples():\n",
    "            rev = str(row[2])\n",
    "            rev = text_to_word_sequence(rev)\n",
    "            temp.append(rev)\n",
    "        self.num_words = num_words\n",
    "        te2 = []\n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp[i])):\n",
    "                te2.append(temp[i][j])\n",
    "        q = Counter(te2)\n",
    "        le = q.most_common(num_words - 1)\n",
    "        temp = le[0:num_words - 1]\n",
    "        self.words = []\n",
    "        for item in temp:\n",
    "            self.words.append(item[0])\n",
    "        # print(self.words)\n",
    "        \n",
    "    def tagging(self, sentence):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for i in range(len(words)):\n",
    "            try:\n",
    "                temp = int(words[i])\n",
    "                if len(words[i]) == 10 and int(temp / 1000000000) >= 7:\n",
    "                    words[i] = '<ph>'\n",
    "                    continue\n",
    "                if len(words[i]) == 12 and int(temp / 100000000000) == 9 and int(temp / 10000000000) == 1 and int(temp / 1000000000) >= 7:\n",
    "                    words[i] = '<ph>'\n",
    "                    continue\n",
    "                if len(words[i]) == 11 and int(temp / 10000000000) == 0 and int(temp / 1000000000) >= 7:\n",
    "                    words[i] = '<ph>'\n",
    "                    continue\n",
    "            except Exception:\n",
    "                pass\n",
    "            if words[i] not in self.words:\n",
    "                words[i] = '<unk>'\n",
    "                continue\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:45:45.293978Z",
     "start_time": "2018-05-23T05:45:45.284005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                                msg\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6      ham  Even my brother is not like to speak with me. ...\n",
      "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8     spam  WINNER!! As a valued network customer you have...\n",
      "9     spam  Had your mobile 11 months or more? U R entitle...\n",
      "10     ham  I'm gonna be home soon and i don't want to tal...\n",
      "11    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12    spam  URGENT! You have won a 1 week FREE membership ...\n",
      "13     ham  I've been searching for the right words to tha...\n",
      "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15    spam  XXXMobileMovieClub: To use your credit, click ...\n",
      "16     ham                         Oh k...i'm watching here:)\n",
      "17     ham  Eh u remember how 2 spell his name... Yes i di...\n",
      "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
      "19    spam  England v Macedonia - dont miss the goals/team...\n",
      "20     ham          Is that seriously how you spell his name?\n",
      "21     ham  IÛ÷m going to try for 2 months ha ha only joking\n",
      "22     ham  So Ì_ pay first lar... Then when is da stock c...\n",
      "23     ham  Aft i finish my lunch then i go str down lor. ...\n",
      "24     ham  Ffffffffff. Alright no way I can meet up with ...\n",
      "25     ham  Just forced myself to eat a slice. I'm really ...\n",
      "26     ham                     Lol your always so convincing.\n",
      "27     ham  Did you catch the bus ? Are you frying an egg ...\n",
      "28     ham  I'm back &amp; we're packing the car now, I'll...\n",
      "29     ham  Ahhh. Work. I vaguely remember that! What does...\n",
      "...    ...                                                ...\n",
      "4537   ham  Welcome to Jio-Bihar & Jharkhand. Enjoy Free I...\n",
      "4538   ham  Welcome to Jio-Bihar & Jharkhand. Enjoy Free I...\n",
      "4539   ham  You have used 50% of your 1 GB daily high spee...\n",
      "4540  spam  Now streaming on JioCinema- Romil and Jugal, a...\n",
      "4541  spam  Nothing says 'I love you' better than JioMusic...\n",
      "4542  spam  For Just Rs 3.50/day enjoy unlimited voice and...\n",
      "4543  spam  For Just Rs 3.50/day enjoy unlimited voice and...\n",
      "4544   ham  You have used 50% of your 1 GB daily high spee...\n",
      "4545  spam  Go cashless anytime, anywhere with BHIM. Downl...\n",
      "4546   ham  Public is hereby cautioned to be extra careful...\n",
      "4547  spam  For Just Rs 3.50/day enjoy unlimited voice and...\n",
      "4548   ham  Dear Customer, \\n345393 is your one time passw...\n",
      "4549   ham  Dear Customer, \\n075355 is your one time passw...\n",
      "4550   ham  Welcome to Jio-Bihar & Jharkhand. Enjoy Free I...\n",
      "4551   ham  Welcome to Jio-Bihar & Jharkhand. Enjoy Free I...\n",
      "4552  spam  All new channel Discovery JEET, now streaming ...\n",
      "4553  spam  For Just Rs 3.50/day enjoy unlimited voice and...\n",
      "4554   ham  మీరు మీ యొక్క1 GB లో 50% ఉపయోగించారు, రోజువారీ...\n",
      "4555   ham  మీ జియో నంబర్ 8639417540 పై 1 GB హై స్పీడ్ ఇంట...\n",
      "4556   ham  You have used 50% of your 1 GB daily high spee...\n",
      "4557  spam  MAKE THE MOST OF FEBRUARY @ Cafe Coffee Day! C...\n",
      "4558  spam  FreeCharge offer! Get Rs.20 cashback on min. R...\n",
      "4559   ham  OTP for transaction IRCTC-RAILWAY TICKET BOOKI...\n",
      "4560   ham  OTP for transaction IRCTC-RAILWAY TICKET BOOKI...\n",
      "4561   ham  730710 is your One Time Password for online pu...\n",
      "4562  spam  AUTOCAD,CATIA,STAAD-PRO,PRO-E,SOLID MORK,3D-MA...\n",
      "4563   ham  Rs. 100 has been paid to REAL APPU GHAR (72777...\n",
      "4564   ham  Paid Rs.7100.00  to yash mobile at 6:46 PM. Or...\n",
      "4565   ham  Dear SBI UPI User, your account is debited INR...\n",
      "4566   ham  Dear SBI UPI User, your account is debited INR...\n",
      "\n",
      "[10139 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:46:10.760001Z",
     "start_time": "2018-05-23T05:46:08.006836Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = userfunc()\n",
    "func.fit_texts(data, 2500)\n",
    "sentences = []\n",
    "pro_data = []\n",
    "for row in data.itertuples():\n",
    "    rev = str(row[2])\n",
    "    words = func.tagging(rev)\n",
    "    \n",
    "    if(len(words) == 0):\n",
    "        pro_data.append(words)\n",
    "        continue\n",
    "    \n",
    "    if(len(words) == 1):\n",
    "        te = ['</s>', words[0], '</e>']\n",
    "        sentences.append(te)\n",
    "        pro_data.append(words)\n",
    "        continue\n",
    "    \n",
    "    te = ['</s>', words[0], words[1]]\n",
    "    sentences.append(te)\n",
    "    \n",
    "    for i in range(1,len(words) - 1):\n",
    "        te = [words[i-1], words[i], words[i+1]]\n",
    "        sentences.append(te)\n",
    "        \n",
    "    te = [words[len(words) - 2], words[len(words) - 1], '</e>']\n",
    "    sentences.append(te)   \n",
    "    \n",
    "    pro_data.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:30:11.013117Z",
     "start_time": "2018-05-17T14:30:10.542936Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting sentences to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:46:24.068605Z",
     "start_time": "2018-05-23T05:46:13.707267Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "size = 150\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences, min_count=1, size = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:46:24.088553Z",
     "start_time": "2018-05-23T05:46:24.069602Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  5.34349643e-02,  -8.28279927e-02,  -3.04530114e-01,\n",
       "        -2.92687304e-03,   3.05641126e-02,  -8.37659910e-02,\n",
       "        -3.81618261e-01,  -5.84747419e-02,   3.39532584e-01,\n",
       "         1.46956906e-01,  -1.15555443e-01,   5.74593619e-03,\n",
       "        -9.34430212e-02,  -4.26470600e-02,   1.24126196e-01,\n",
       "         1.41835898e-01,   6.90416107e-03,   2.32995842e-02,\n",
       "        -4.87964936e-02,  -1.41508028e-01,  -2.83192489e-02,\n",
       "         1.29032349e-02,  -3.76755983e-01,   1.19415380e-01,\n",
       "        -6.57896176e-02,   1.48873478e-01,  -3.25506479e-02,\n",
       "        -9.69072357e-02,  -4.35165137e-01,   1.42433122e-01,\n",
       "        -1.59223992e-02,   9.08298120e-02,   6.98206723e-02,\n",
       "        -1.75857335e-01,   3.03316921e-01,   1.22041456e-01,\n",
       "         3.32557648e-01,   7.61111230e-02,  -1.56478032e-01,\n",
       "         1.64893731e-01,   2.89157957e-01,   3.20526212e-01,\n",
       "        -2.91972131e-01,   1.99173510e-01,  -1.68617025e-01,\n",
       "        -4.11446095e-02,   1.45367801e-01,   1.55002698e-01,\n",
       "         1.68593466e-01,  -1.12712301e-01,  -1.58459127e-01,\n",
       "         3.49174798e-01,   1.71257958e-01,  -2.04616025e-01,\n",
       "        -3.96886058e-02,   6.21773340e-02,   2.28496753e-02,\n",
       "         1.71856195e-01,   1.75595939e-01,  -4.34542820e-02,\n",
       "         2.06254004e-03,   3.83274585e-01,  -2.39045799e-01,\n",
       "        -2.70176888e-01,   1.97187796e-01,  -1.13675840e-01,\n",
       "        -1.58358738e-01,  -1.46100014e-01,   1.42428023e-03,\n",
       "        -6.84213936e-02,   8.35458264e-02,   3.91213387e-01,\n",
       "         2.90061384e-02,  -1.01570614e-01,  -5.04129715e-02,\n",
       "         4.50323597e-02,  -1.29129514e-01,   5.38920574e-02,\n",
       "        -1.53396148e-02,  -4.84983288e-02,   4.94739152e-02,\n",
       "         2.45869495e-02,  -2.87688579e-02,   3.22066605e-01,\n",
       "         6.35314882e-02,  -2.25467473e-01,  -3.91351044e-01,\n",
       "        -1.39146224e-01,   2.59185642e-01,  -1.18574342e-02,\n",
       "        -1.49353314e-02,   1.01768427e-01,  -2.01252550e-01,\n",
       "        -4.51811217e-03,  -5.86704947e-02,   9.91016552e-02,\n",
       "        -2.33200982e-01,  -3.21533680e-02,   3.10227782e-01,\n",
       "        -1.16853610e-01,   2.37217024e-01,  -8.02800879e-02,\n",
       "         2.02025231e-02,  -3.25569510e-01,   4.32344824e-02,\n",
       "         1.19801350e-01,   5.34463264e-02,   8.29516277e-02,\n",
       "        -2.22164705e-01,  -7.84501806e-03,  -1.83536530e-01,\n",
       "        -2.36574024e-01,  -1.12146847e-01,  -1.18280374e-01,\n",
       "        -2.32728407e-01,  -5.69705486e-01,   7.31774941e-02,\n",
       "         3.83218601e-02,  -3.13755602e-01,  -1.41400471e-01,\n",
       "         7.05590099e-02,   2.26228461e-02,  -2.17086330e-01,\n",
       "         2.15876982e-01,   2.55887449e-01,   4.19607610e-02,\n",
       "         1.89403862e-01,   2.26166546e-02,  -1.13371044e-01,\n",
       "         1.87334135e-01,  -1.69618800e-01,  -7.45157003e-02,\n",
       "         2.76640349e-04,  -1.47291288e-01,  -2.06491686e-02,\n",
       "         6.16516769e-02,  -3.53607945e-02,  -1.81487083e-01,\n",
       "         3.93449552e-02,   3.41326952e-01,   9.98347774e-02,\n",
       "         9.31439176e-03,   5.98961823e-02,  -2.39757355e-02,\n",
       "         1.36938784e-02,  -1.53069258e-01,  -1.30461037e-01,\n",
       "         8.51535127e-02,   1.36602804e-01,   1.91513255e-01], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['god']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:47:58.911191Z",
     "start_time": "2018-05-23T05:47:29.330531Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "data_vec = []\n",
    "msg_limit = 160\n",
    "for i in range(len(pro_data)):\n",
    "    empty = [0 for i in range(size)]\n",
    "    temp = [[0 for i in range(size)] for j in range(msg_limit)]\n",
    "    for j in range(len(pro_data[i])-1, -1, -1):\n",
    "        temp[159 - (len(pro_data[i])-1-j)] = model[pro_data[i][j]]\n",
    "    data_vec.append(temp)\n",
    "data_vec = np.array(data_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:30:42.157006Z",
     "start_time": "2018-05-17T14:30:42.153987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10139, 160, 150)\n"
     ]
    }
   ],
   "source": [
    "print(data_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:48:13.096083Z",
     "start_time": "2018-05-23T05:48:09.041673Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_vec, data['label'], test_size=0.30, random_state=0)\n",
    "\n",
    "Y_train = pd.get_dummies(Y_train).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:48:14.648457Z",
     "start_time": "2018-05-23T05:48:13.770296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 200)               280800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 281,202\n",
      "Trainable params: 281,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(LSTM(200, input_shape =(160, size)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(2, activation='softmax'))\n",
    "classifier.compile(\n",
    "    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:55:44.677944Z",
     "start_time": "2018-05-23T05:48:16.097439Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7097/7097 [==============================] - 55s 8ms/step - loss: 0.1999 - acc: 0.9249\n",
      "Epoch 2/10\n",
      "7097/7097 [==============================] - 43s 6ms/step - loss: 0.1293 - acc: 0.9524\n",
      "Epoch 3/10\n",
      "7097/7097 [==============================] - 43s 6ms/step - loss: 0.1112 - acc: 0.9596\n",
      "Epoch 4/10\n",
      "7097/7097 [==============================] - 42s 6ms/step - loss: 0.0952 - acc: 0.9662\n",
      "Epoch 5/10\n",
      "7097/7097 [==============================] - 43s 6ms/step - loss: 0.0852 - acc: 0.9696\n",
      "Epoch 6/10\n",
      "7097/7097 [==============================] - 43s 6ms/step - loss: 0.0716 - acc: 0.9746\n",
      "Epoch 7/10\n",
      "7097/7097 [==============================] - 44s 6ms/step - loss: 0.0623 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "7097/7097 [==============================] - 47s 7ms/step - loss: 0.0586 - acc: 0.9813\n",
      "Epoch 9/10\n",
      "7097/7097 [==============================] - 45s 6ms/step - loss: 0.0488 - acc: 0.9838\n",
      "Epoch 10/10\n",
      "7097/7097 [==============================] - 43s 6ms/step - loss: 0.0393 - acc: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a22e53bf98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, Y_train, epochs = 10, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:55:59.369596Z",
     "start_time": "2018-05-23T05:55:53.273916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pr = classifier.predict(X_test)\n",
    "\n",
    "Y_pred = []\n",
    "\n",
    "for i in range(len(Y_pr)):\n",
    "    if Y_pr[i][0] >= Y_pr[i][1]:\n",
    "        Y_pred.append('ham')\n",
    "    else:\n",
    "        Y_pred.append('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:55:59.405501Z",
     "start_time": "2018-05-23T05:55:59.370593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2380   58]\n",
      " [  60  544]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)  \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T05:57:31.450407Z",
     "start_time": "2018-05-23T05:57:31.367629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham - 98.06%\n",
      "Spam - 1.94%\n"
     ]
    }
   ],
   "source": [
    "sms = 'Mega 6 lakh rupee game join us for our biggest game on loco'\n",
    "sms = func.tagging(sms)\n",
    "\n",
    "data_vec = []\n",
    "msg_limit = 160\n",
    "empty = [0 for i in range(size)]\n",
    "temp = [[0 for i in range(size)] for j in range(msg_limit)]\n",
    "for j in range(len(sms)-1, -1, -1):\n",
    "    temp[159 - (len(sms)-1-j)] = model[sms[j]]\n",
    "data_vec.append(temp)\n",
    "data_vec = np.array(data_vec)\n",
    "\n",
    "ma = classifier.predict(data_vec)\n",
    "print('Ham - %.2f'%(ma[0][0] * 100) + '%')\n",
    "print('Spam - %.2f'%(ma[0][1] * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
