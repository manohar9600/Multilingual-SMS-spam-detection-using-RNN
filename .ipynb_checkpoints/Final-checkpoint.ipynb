{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:06.723347Z",
     "start_time": "2018-05-04T06:27:00.326442Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:06.947707Z",
     "start_time": "2018-05-04T06:27:06.725331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle dataset head:\n",
      "Our dataset head:\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('Resources/spam.csv', encoding = 'latin-1') # Kaggle dataset\n",
    "data1 = data1.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
    "print(\"Kaggle dataset head:\")\n",
    "data1.head()\n",
    "\n",
    "data2 = pd.ExcelFile('Resources/revisedindiandataset.xls')\n",
    "data2 = data2.parse(0)\n",
    "data2 = data2.drop(['code'], axis = 1)\n",
    "print(\"Our dataset head:\")\n",
    "data2.head()\n",
    "\n",
    "data = pd.concat([data1, data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:07.005589Z",
     "start_time": "2018-05-04T06:27:06.949702Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class userfunc:\n",
    "\n",
    "    def fit_texts(self, data, num_words):\n",
    "        temp = []\n",
    "        for row in data.itertuples():\n",
    "            rev = str(row[2])\n",
    "            rev = text_to_word_sequence(rev)\n",
    "            temp.append(rev)\n",
    "        self.num_words = num_words\n",
    "        te2 = []\n",
    "        for i in range(len(temp)):\n",
    "            for j in range(len(temp[i])):\n",
    "                te2.append(temp[i][j])\n",
    "        q = Counter(te2)\n",
    "        le = q.most_common(num_words - 1)\n",
    "        temp = le[0:num_words - 1]\n",
    "        self.words = []\n",
    "        for item in temp:\n",
    "            self.words.append(item[0])\n",
    "        # print(self.words)\n",
    "        \n",
    "    def tagging(self, sentence):\n",
    "        words = text_to_word_sequence(sentence)\n",
    "        for i in range(len(words)):\n",
    "            try:\n",
    "                temp = int(words[i])\n",
    "                if len(words[i]) == 10 and int(temp / 1000000000) >= 7:\n",
    "                    words[i] = '<ph>'\n",
    "                    continue\n",
    "                if len(words[i]) == 12 and int(temp / 100000000000) == 9 and int(temp / 10000000000) == 1 and int(temp / 1000000000) >= 7:\n",
    "                    words[i] = '<ph>'\n",
    "                    continue\n",
    "                if len(words[i]) == 11 and int(temp / 10000000000) == 0 and int(temp / 1000000000) >= 7:\n",
    "                    words[i] = '<ph>'\n",
    "                    continue\n",
    "            except Exception:\n",
    "                pass\n",
    "            if words[i] not in self.words:\n",
    "                words[i] = '<unk>'\n",
    "                continue\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:07.255958Z",
     "start_time": "2018-05-04T06:27:07.007547Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                                msg\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6      ham  Even my brother is not like to speak with me. ...\n",
      "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8     spam  WINNER!! As a valued network customer you have...\n",
      "9     spam  Had your mobile 11 months or more? U R entitle...\n",
      "10     ham  I'm gonna be home soon and i don't want to tal...\n",
      "11    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12    spam  URGENT! You have won a 1 week FREE membership ...\n",
      "13     ham  I've been searching for the right words to tha...\n",
      "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15    spam  XXXMobileMovieClub: To use your credit, click ...\n",
      "16     ham                         Oh k...i'm watching here:)\n",
      "17     ham  Eh u remember how 2 spell his name... Yes i di...\n",
      "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
      "19    spam  England v Macedonia - dont miss the goals/team...\n",
      "20     ham          Is that seriously how you spell his name?\n",
      "21     ham  IÛ÷m going to try for 2 months ha ha only joking\n",
      "22     ham  So Ì_ pay first lar... Then when is da stock c...\n",
      "23     ham  Aft i finish my lunch then i go str down lor. ...\n",
      "24     ham  Ffffffffff. Alright no way I can meet up with ...\n",
      "25     ham  Just forced myself to eat a slice. I'm really ...\n",
      "26     ham                     Lol your always so convincing.\n",
      "27     ham  Did you catch the bus ? Are you frying an egg ...\n",
      "28     ham  I'm back &amp; we're packing the car now, I'll...\n",
      "29     ham  Ahhh. Work. I vaguely remember that! What does...\n",
      "...    ...                                                ...\n",
      "4537   ham  Welcome to Jio-Bihar & Jharkhand. Enjoy Free I...\n",
      "4538   ham  Welcome to Jio-Bihar & Jharkhand. Enjoy Free I...\n",
      "4539   ham  You have used 50% of your 1 GB daily high spee...\n",
      "4540  spam  Now streaming on JioCinema- Romil and Jugal, a...\n",
      "4541  spam  Nothing says 'I love you' better than JioMusic...\n",
      "4542  spam  For Just Rs 3.50/day enjoy unlimited voice and...\n",
      "4543  spam  For Just Rs 3.50/day enjoy unlimited voice and...\n",
      "4544   ham  You have used 50% of your 1 GB daily high spee...\n",
      "4545  spam  Go cashless anytime, anywhere with BHIM. Downl...\n",
      "4546   ham  Public is hereby cautioned to be extra careful...\n",
      "4547  spam  For Just Rs 3.50/day enjoy unlimited voice and...\n",
      "4548   ham  Dear Customer, \\n345393 is your one time passw...\n",
      "4549   ham  Dear Customer, \\n075355 is your one time passw...\n",
      "4550   ham  Welcome to Jio-Bihar & Jharkhand. Enjoy Free I...\n",
      "4551   ham  Welcome to Jio-Bihar & Jharkhand. Enjoy Free I...\n",
      "4552  spam  All new channel Discovery JEET, now streaming ...\n",
      "4553  spam  For Just Rs 3.50/day enjoy unlimited voice and...\n",
      "4554   ham  మీరు మీ యొక్క1 GB లో 50% ఉపయోగించారు, రోజువారీ...\n",
      "4555   ham  మీ జియో నంబర్ 8639417540 పై 1 GB హై స్పీడ్ ఇంట...\n",
      "4556   ham  You have used 50% of your 1 GB daily high spee...\n",
      "4557  spam  MAKE THE MOST OF FEBRUARY @ Cafe Coffee Day! C...\n",
      "4558  spam  FreeCharge offer! Get Rs.20 cashback on min. R...\n",
      "4559   ham  OTP for transaction IRCTC-RAILWAY TICKET BOOKI...\n",
      "4560   ham  OTP for transaction IRCTC-RAILWAY TICKET BOOKI...\n",
      "4561   ham  730710 is your One Time Password for online pu...\n",
      "4562  spam  AUTOCAD,CATIA,STAAD-PRO,PRO-E,SOLID MORK,3D-MA...\n",
      "4563   ham  Rs. 100 has been paid to REAL APPU GHAR (72777...\n",
      "4564   ham  Paid Rs.7100.00  to yash mobile at 6:46 PM. Or...\n",
      "4565   ham  Dear SBI UPI User, your account is debited INR...\n",
      "4566   ham  Dear SBI UPI User, your account is debited INR...\n",
      "\n",
      "[10139 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:09.837308Z",
     "start_time": "2018-05-04T06:27:07.257945Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = userfunc()\n",
    "func.fit_texts(data, 2500)\n",
    "sentences = []\n",
    "pro_data = []\n",
    "for row in data.itertuples():\n",
    "    rev = str(row[2])\n",
    "    words = func.tagging(rev)\n",
    "    \n",
    "    if(len(words) == 0):\n",
    "        pro_data.append(words)\n",
    "        continue\n",
    "    \n",
    "    if(len(words) == 1):\n",
    "        te = ['</s>', words[0], '</e>']\n",
    "        sentences.append(te)\n",
    "        pro_data.append(words)\n",
    "        continue\n",
    "    \n",
    "    te = ['</s>', words[0], words[1]]\n",
    "    sentences.append(te)\n",
    "    \n",
    "    for i in range(1,len(words) - 1):\n",
    "        te = [words[i-1], words[i], words[i+1]]\n",
    "        sentences.append(te)\n",
    "        \n",
    "    te = [words[len(words) - 2], words[len(words) - 1], '</e>']\n",
    "    sentences.append(te)   \n",
    "    \n",
    "    pro_data.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:10.237514Z",
     "start_time": "2018-05-04T06:27:09.839306Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting sentences to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:13.201858Z",
     "start_time": "2018-05-04T06:27:10.239475Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "size = 150\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences, min_count=1, size = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:13.215827Z",
     "start_time": "2018-05-04T06:27:13.202855Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -1.18726023e-01,   1.51656941e-01,   2.09653065e-01,\n",
       "         1.05604725e-02,   5.20429984e-02,   1.14890687e-01,\n",
       "        -5.03857387e-03,   5.46522327e-02,   1.00811534e-01,\n",
       "        -2.43850231e-01,   2.74993535e-02,  -4.25761752e-02,\n",
       "         1.15098839e-04,  -5.14477678e-03,  -5.13178222e-02,\n",
       "         1.37933955e-01,  -7.43475929e-02,   2.04726495e-02,\n",
       "         5.28861247e-02,   1.92470420e-02,   1.33356959e-01,\n",
       "         1.58915550e-01,   1.52429081e-02,   2.57646114e-01,\n",
       "         6.66579455e-02,  -3.04877996e-01,  -3.03308338e-01,\n",
       "        -2.15643287e-01,  -2.28475809e-01,   6.27081245e-02,\n",
       "         5.33002138e-04,   4.08287197e-02,   2.78862447e-01,\n",
       "         2.99505085e-01,  -1.35530010e-01,   1.03885708e-02,\n",
       "        -5.15876353e-01,   6.81975633e-02,   2.00393074e-03,\n",
       "        -3.82964462e-02,   1.26279697e-01,   1.07255116e-01,\n",
       "        -4.01777625e-02,   1.70381427e-01,   8.18100274e-02,\n",
       "         6.69106320e-02,   2.62455437e-02,  -1.04115635e-01,\n",
       "         3.45454723e-01,   5.69079518e-02,  -2.45578602e-01,\n",
       "        -2.68933117e-01,  -5.43172620e-02,  -1.36915877e-01,\n",
       "         1.94829613e-01,   9.33490917e-02,  -3.06364000e-01,\n",
       "         1.58570185e-01,   4.45818692e-01,  -3.06565672e-01,\n",
       "         2.90822680e-03,  -1.12109400e-01,  -8.04304555e-02,\n",
       "         1.17056379e-02,  -8.22584182e-02,   1.77489579e-01,\n",
       "         5.30166887e-02,  -2.31170759e-01,  -1.53290942e-01,\n",
       "        -5.74025102e-02,  -2.10438415e-01,  -5.30680157e-02,\n",
       "         4.06348668e-02,  -1.55565068e-01,  -3.78753841e-01,\n",
       "        -1.09371960e-01,  -9.47633311e-02,   1.33260712e-01,\n",
       "        -5.28436303e-02,  -2.66556621e-01,   2.21733660e-01,\n",
       "        -2.77811009e-02,  -2.43026674e-01,  -1.32629350e-01,\n",
       "        -1.37110189e-01,   1.83618098e-01,  -1.08583376e-01,\n",
       "         5.38061596e-02,  -4.67076927e-01,  -3.50080011e-03,\n",
       "         1.76340893e-01,   1.35876834e-01,  -1.06712701e-02,\n",
       "        -1.05239429e-01,  -2.52500296e-01,   1.73943445e-01,\n",
       "        -2.14459691e-02,   1.83593884e-01,   1.97280377e-01,\n",
       "        -6.05941266e-02,   4.90296781e-01,   1.03602737e-01,\n",
       "         3.16889919e-02,   9.32961926e-02,   6.59497604e-02,\n",
       "         1.88185394e-01,   2.55638719e-01,   3.38737033e-02,\n",
       "        -7.13084638e-02,   5.77521957e-02,  -2.93903261e-01,\n",
       "        -5.84609434e-02,   2.32712269e-01,  -1.27944440e-01,\n",
       "        -1.86326563e-01,   6.15766533e-02,  -1.72121376e-02,\n",
       "        -1.01528876e-02,   1.07675567e-02,  -1.11458123e-01,\n",
       "        -7.31848404e-02,  -1.65321529e-01,  -7.31314421e-02,\n",
       "        -2.22013876e-01,  -2.94162273e-01,   1.99978173e-01,\n",
       "        -5.31185046e-02,  -5.34377322e-02,  -2.87009254e-02,\n",
       "         1.33384109e-01,  -9.44571570e-02,   2.70379726e-02,\n",
       "         1.28379345e-01,  -1.49522036e-01,  -1.17582676e-03,\n",
       "         3.67127322e-02,   8.80299583e-02,   5.36745833e-03,\n",
       "        -5.85399568e-02,  -1.21557742e-01,  -1.04030684e-01,\n",
       "         4.96794909e-01,  -1.39125124e-01,   1.79548666e-01,\n",
       "        -3.78521755e-02,  -1.68890566e-01,  -1.67387754e-01,\n",
       "         4.22136068e-01,  -1.54710859e-01,  -2.89017018e-02], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['god']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:40.728985Z",
     "start_time": "2018-05-04T06:27:13.217816Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "data_vec = []\n",
    "msg_limit = 160\n",
    "for i in range(len(pro_data)):\n",
    "    empty = [0 for i in range(size)]\n",
    "    temp = [[0 for i in range(size)] for j in range(msg_limit)]\n",
    "    for j in range(len(pro_data[i])-1, -1, -1):\n",
    "        temp[159 - (len(pro_data[i])-1-j)] = model[pro_data[i][j]]\n",
    "    data_vec.append(temp)\n",
    "data_vec = np.array(data_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:40.736813Z",
     "start_time": "2018-05-04T06:27:40.730828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10139, 160, 150)\n"
     ]
    }
   ],
   "source": [
    "print(data_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:42.212605Z",
     "start_time": "2018-05-04T06:27:40.739804Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_vec, data['label'], test_size=0.30, random_state=0)\n",
    "\n",
    "Y_train = pd.get_dummies(Y_train).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:27:42.432786Z",
     "start_time": "2018-05-04T06:27:42.214371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 200)               280800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 281,202\n",
      "Trainable params: 281,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(LSTM(200, input_shape =(160, size)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(2, activation='softmax'))\n",
    "classifier.compile(\n",
    "    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:31:47.178936Z",
     "start_time": "2018-05-04T06:27:42.434781Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "7097/7097 [==============================] - 35s 5ms/step - loss: 0.2100 - acc: 0.9162\n",
      "Epoch 2/7\n",
      "7097/7097 [==============================] - 35s 5ms/step - loss: 0.1272 - acc: 0.9548\n",
      "Epoch 3/7\n",
      "7097/7097 [==============================] - 36s 5ms/step - loss: 0.1042 - acc: 0.9607\n",
      "Epoch 4/7\n",
      "7097/7097 [==============================] - 34s 5ms/step - loss: 0.0912 - acc: 0.9655\n",
      "Epoch 5/7\n",
      "7097/7097 [==============================] - 34s 5ms/step - loss: 0.0769 - acc: 0.9721\n",
      "Epoch 6/7\n",
      "7097/7097 [==============================] - 34s 5ms/step - loss: 0.0750 - acc: 0.9714\n",
      "Epoch 7/7\n",
      "7097/7097 [==============================] - 35s 5ms/step - loss: 0.0618 - acc: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17115932978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, Y_train, epochs = 7, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:31:52.487863Z",
     "start_time": "2018-05-04T06:31:47.180928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pr = classifier.predict(X_test)\n",
    "\n",
    "Y_pred = []\n",
    "\n",
    "for i in range(len(Y_pr)):\n",
    "    if Y_pr[i][0] >= Y_pr[i][1]:\n",
    "        Y_pred.append('ham')\n",
    "    else:\n",
    "        Y_pred.append('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:31:52.608541Z",
     "start_time": "2018-05-04T06:31:52.489856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2370   68]\n",
      " [  57  547]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)  \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T06:42:03.917772Z",
     "start_time": "2018-05-04T06:42:03.654267Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham - 99.88%\n",
      "Spam - 0.12%\n"
     ]
    }
   ],
   "source": [
    "sms = 'Don\\'t buy, just subscribe your personal car at a fixed monthly fee with ZAP. Pay Rs 999/- to pre-book your car. Booking starts @11 am. bit.ly/2BYrO3p'\n",
    "sms = func.tagging(sms)\n",
    "\n",
    "data_vec = []\n",
    "msg_limit = 160\n",
    "empty = [0 for i in range(size)]\n",
    "temp = [[0 for i in range(size)] for j in range(msg_limit)]\n",
    "for j in range(len(sms)-1, -1, -1):\n",
    "    temp[159 - (len(sms)-1-j)] = model[sms[j]]\n",
    "data_vec.append(temp)\n",
    "data_vec = np.array(data_vec)\n",
    "\n",
    "ma = classifier.predict(data_vec)\n",
    "print('Ham - %.2f'%(ma[0][0] * 100) + '%')\n",
    "print('Spam - %.2f'%(ma[0][1] * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
