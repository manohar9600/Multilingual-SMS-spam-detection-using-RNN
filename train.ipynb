{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T08:28:39.784901Z",
     "start_time": "2018-02-22T08:28:34.580010Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T08:28:39.847679Z",
     "start_time": "2018-02-22T08:28:39.785905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                msg Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Resources/spam.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T08:28:39.956513Z",
     "start_time": "2018-02-22T08:28:39.851695Z"
    }
   },
   "outputs": [],
   "source": [
    "list = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
    "data = data.drop(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T08:30:21.299768Z",
     "start_time": "2018-02-22T08:28:39.959556Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoh\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# loading the downloaded model\n",
    "w2v = KeyedVectors.load_word2vec_format(\n",
    "    'Resources/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below Function going to break after fullstop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T08:30:55.251139Z",
     "start_time": "2018-02-22T08:30:55.226531Z"
    }
   },
   "outputs": [],
   "source": [
    "def breakdot(word):\n",
    "    tem = []\n",
    "    fa = 0\n",
    "    for i in range(len(word)):\n",
    "        if word[i] == '.':\n",
    "            fa = fa + 1\n",
    "        if fa == 2:\n",
    "            break\n",
    "    if fa < 2:\n",
    "        tem = word.split('.')\n",
    "        return tem\n",
    "    else:\n",
    "        tem.append(word)\n",
    "        return tem\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In below block data broken into words and got vector from each word. Ignoring unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:51:36.989690Z",
     "start_time": "2018-02-22T10:51:34.191301Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2vec = []\n",
    "for row in data.itertuples():\n",
    "    temp = np.ndarray(shape=(1, 300), dtype='float')\n",
    "    #t = 0\n",
    "    words = row[2].lower()\n",
    "    words = words.split()\n",
    "    for word in words:\n",
    "        te = breakdot(word)\n",
    "        for q in te:\n",
    "            try:\n",
    "                #if t <= 30:\n",
    "                mod = w2v[q].reshape(1, 300)\n",
    "                temp = np.concatenate((temp, mod), axis=0)\n",
    "                #temp.append(mod.reshape(1, 300))\n",
    "                t = t + 1\n",
    "            except Exception:\n",
    "                pass\n",
    "        \"\"\"while t <= 30:\n",
    "            mod = np.zeros((1, 300))\n",
    "            temp = np.concatenate((temp, mod), axis=0)\n",
    "            #temp.append(mod)\n",
    "            t = t + 1\"\"\"\n",
    "    temp = np.delete(temp,0,0)\n",
    "    data2vec.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T13:33:59.762194Z",
     "start_time": "2018-02-21T13:33:59.737961Z"
    }
   },
   "source": [
    "Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:51:38.554013Z",
     "start_time": "2018-02-22T10:51:38.518314Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data2vec, data['label'], test_size=0.30, random_state=42)\n",
    "\n",
    "# getting dummies\n",
    "Y_train = pd.get_dummies(Y_train).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:51:41.254001Z",
     "start_time": "2018-02-22T10:51:41.030572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 31, 300)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desigining classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:51:51.539649Z",
     "start_time": "2018-02-22T10:51:50.660582Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(12, input_shape=(None, 300..., dropout=0.2, recurrent_dropout=0.2)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Input\n",
    "\n",
    "\n",
    "I = Input(shape=(None, 300))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(12, dropout_U=0.2, dropout_W=0.2,\n",
    "               input_shape=(None,300)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:54:53.360373Z",
     "start_time": "2018-02-22T10:51:54.271861Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoh\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      " - 18s - loss: 0.4502 - acc: 0.8633\n",
      "Epoch 2/12\n",
      " - 14s - loss: 0.3839 - acc: 0.8641\n",
      "Epoch 3/12\n",
      " - 14s - loss: 0.3677 - acc: 0.8692\n",
      "Epoch 4/12\n",
      " - 14s - loss: 0.3554 - acc: 0.8669\n",
      "Epoch 5/12\n",
      " - 13s - loss: 0.3462 - acc: 0.8715\n",
      "Epoch 6/12\n",
      " - 14s - loss: 0.3412 - acc: 0.8731\n",
      "Epoch 7/12\n",
      " - 15s - loss: 0.3403 - acc: 0.8690\n",
      "Epoch 8/12\n",
      " - 16s - loss: 0.3342 - acc: 0.8690\n",
      "Epoch 9/12\n",
      " - 14s - loss: 0.3263 - acc: 0.8777\n",
      "Epoch 10/12\n",
      " - 15s - loss: 0.3273 - acc: 0.8738\n",
      "Epoch 11/12\n",
      " - 14s - loss: 0.3272 - acc: 0.8800\n",
      "Epoch 12/12\n",
      " - 15s - loss: 0.3300 - acc: 0.8659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x192e2bb0e10>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "model.fit(X_train, Y_train, nb_epoch = 12, batch_size = batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:54:59.924193Z",
     "start_time": "2018-02-22T10:54:58.096193Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "Y_te = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:55:01.714254Z",
     "start_time": "2018-02-22T10:55:01.703939Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = []\n",
    "for i in range(Y_te.shape[0]):\n",
    "    if Y_te[i][0] >= Y_te[i][1]:\n",
    "        Y_pred.append('ham')\n",
    "    else:\n",
    "        Y_pred.append('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T10:55:05.441954Z",
     "start_time": "2018-02-22T10:55:04.609003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1369   84]\n",
      " [ 149   70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
