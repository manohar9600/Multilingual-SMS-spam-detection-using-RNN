{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:21:25.246758Z",
     "start_time": "2018-05-17T14:21:16.721645Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:21:26.924173Z",
     "start_time": "2018-05-17T14:21:26.670880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                                msg\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "  label                                                msg\n",
      "0   ham  Dear Customer, +916300623587 is now available ...\n",
      "1   ham  Dear Customer, You have a missed call from +91...\n",
      "2  spam  Join Hike to get Rs 40. Earn upto Rs. 10,000 b...\n",
      "3  spam  Just sent you some money and invited you to Hi...\n",
      "4  spam  Just sent you some money and invited you to Hi...\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('spam.csv', encoding = 'latin-1') # Kaggle dataset\n",
    "data1 = data1.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
    "print(data1.head())\n",
    "\n",
    "data2 = pd.ExcelFile('revisedindiandataset.xls')\n",
    "data2 = data2.parse(0)\n",
    "data2 = data2.drop(['code'], axis = 1)\n",
    "print(data2.head())\n",
    "\n",
    "data = pd.concat([data1, data2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing sentences for word2vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:21:29.322312Z",
     "start_time": "2018-05-17T14:21:29.018125Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "pro_data = []\n",
    "for row in data.itertuples():\n",
    "    rev = str(row[2])\n",
    "    words = text_to_word_sequence(rev)\n",
    "    \n",
    "    if(len(words) == 0):\n",
    "        pro_data.append(words)\n",
    "        continue\n",
    "    \n",
    "    if(len(words) == 1):\n",
    "        te = ['</s>', words[0], '</e>']\n",
    "        sentences.append(te)\n",
    "        pro_data.append(words)\n",
    "        continue\n",
    "    \n",
    "    te = ['</s>', words[0], words[1]]\n",
    "    sentences.append(te)\n",
    "    \n",
    "    for i in range(1,len(words) - 1):\n",
    "        te = [words[i-1], words[i], words[i+1]]\n",
    "        sentences.append(te)\n",
    "        \n",
    "    te = [words[len(words) - 2], words[len(words) - 1], '</e>']\n",
    "    sentences.append(te)   \n",
    "    \n",
    "    pro_data.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:21:30.956995Z",
     "start_time": "2018-05-17T14:21:30.951011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "['</s>', 'go', 'until']\n",
      "['go', 'until', 'jurong']\n"
     ]
    }
   ],
   "source": [
    "print(data['msg'].iloc[0])\n",
    "print(sentences[0])\n",
    "print(sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:21:37.407905Z",
     "start_time": "2018-05-17T14:21:33.313371Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "size = 150\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences, min_count=1, size = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:16:54.053577Z",
     "start_time": "2018-05-17T14:16:54.033578Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.16490524, -0.12317795, -0.20400028,  0.50917351, -0.06683756,\n",
       "        0.29778257,  0.01752055, -0.1428301 ,  0.20175029, -0.01860907,\n",
       "       -0.06080187, -0.14596462,  0.02184702,  0.22056867, -0.31917828,\n",
       "        0.00341994,  0.05246627, -0.17653848, -0.15657805,  0.05114596,\n",
       "        0.30727157,  0.05585392, -0.23821613,  0.34458381, -0.61221409,\n",
       "        0.09606561, -0.06882115, -0.27109337, -0.19593148, -0.0268448 ,\n",
       "       -0.1761073 , -0.21702495,  0.19700979,  0.01971228,  0.47714841,\n",
       "        0.03118076, -0.24821253,  0.16127042, -0.27863744,  0.2055781 ,\n",
       "        0.05842168,  0.0051453 , -0.01437454, -0.08824436,  0.22952513,\n",
       "        0.02204015, -0.01527987, -0.39313459,  0.16025591,  0.18031368,\n",
       "       -0.09067744, -0.07197399, -0.05545877,  0.17090571, -0.30757448,\n",
       "       -0.49316847, -0.24528784, -0.209005  , -0.22037736,  0.08996142,\n",
       "       -0.01346877,  0.39833558,  0.16763233,  0.25513238,  0.16989066,\n",
       "        0.09064545, -0.17535852,  0.10748672, -0.07899807, -0.14059117,\n",
       "       -0.36900052, -0.24872467,  0.2163721 , -0.12802441, -0.08598868,\n",
       "       -0.28823051,  0.1889396 , -0.24090774,  0.05889281,  0.10922799,\n",
       "       -0.0723191 ,  0.43329656, -0.10462349, -0.03721195, -0.33127838,\n",
       "        0.03381392, -0.29315385,  0.36640584,  0.04432669, -0.44946465,\n",
       "        0.14994477,  0.02911378, -0.10876907,  0.18672147,  0.07815479,\n",
       "        0.2406635 , -0.1231904 ,  0.42273611, -0.12738058,  0.51056021,\n",
       "       -0.00384172,  0.21053332, -0.00446022,  0.28871375, -0.0786707 ,\n",
       "       -0.28203994, -0.36867556, -0.36018369, -0.06138759,  0.40913194,\n",
       "        0.14314079,  0.07086765,  0.05349438,  0.03010615, -0.19219342,\n",
       "        0.07453264, -0.16066441,  0.27660269,  0.09049363, -0.23415092,\n",
       "       -0.02758869,  0.05147402,  0.05118521, -0.03095015, -0.08661669,\n",
       "       -0.0617379 ,  0.01845652,  0.15740608, -0.28232098, -0.04742536,\n",
       "       -0.15412967, -0.19332026, -0.53110725, -0.10404721, -0.15673155,\n",
       "        0.13248837,  0.22328645, -0.29980925,  0.03932377,  0.14890352,\n",
       "        0.2140144 ,  0.02251848,  0.23416536, -0.00197365, -0.22992945,\n",
       "       -0.00668553, -0.21135893, -0.21310133,  0.31604442,  0.00527831], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['god']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre - padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:22:17.792610Z",
     "start_time": "2018-05-17T14:21:45.591702Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "data_vec = []\n",
    "msg_limit = 200\n",
    "for i in range(len(pro_data)):\n",
    "    empty = [0 for i in range(size)]\n",
    "    temp = [[0 for i in range(size)] for j in range(msg_limit)]\n",
    "    for j in range(len(pro_data[i])-1, -1, -1):\n",
    "        temp[199 - (len(pro_data[i])-1-j)] = model[pro_data[i][j]]\n",
    "    data_vec.append(temp)\n",
    "data_vec = np.array(data_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting data for training and testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:22:26.392467Z",
     "start_time": "2018-05-17T14:22:24.754937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data_vec, data['label'], test_size=0.30, random_state=0)\n",
    "\n",
    "Y_train = pd.get_dummies(Y_train).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:22:29.248308Z",
     "start_time": "2018-05-17T14:22:29.047845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 200)               280800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 281,202\n",
      "Trainable params: 281,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(LSTM(200, input_shape =(200, size)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(2, activation='softmax'))\n",
    "classifier.compile(\n",
    "    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-17T14:28:01.073407Z",
     "start_time": "2018-05-17T14:22:33.052155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "7097/7097 [==============================] - 75s 11ms/step - loss: 0.2326 - acc: 0.9066\n",
      "Epoch 2/7\n",
      "7097/7097 [==============================] - 41s 6ms/step - loss: 0.1402 - acc: 0.9470\n",
      "Epoch 3/7\n",
      "7097/7097 [==============================] - 42s 6ms/step - loss: 0.1120 - acc: 0.9582\n",
      "Epoch 4/7\n",
      "7097/7097 [==============================] - 42s 6ms/step - loss: 0.0983 - acc: 0.9629\n",
      "Epoch 5/7\n",
      "7097/7097 [==============================] - 41s 6ms/step - loss: 0.0914 - acc: 0.9666\n",
      "Epoch 6/7\n",
      "7097/7097 [==============================] - 42s 6ms/step - loss: 0.0757 - acc: 0.9731\n",
      "Epoch 7/7\n",
      "7097/7097 [==============================] - 44s 6ms/step - loss: 0.0682 - acc: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122ed6304e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, Y_train, epochs = 7, batch_size = 50) # training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T10:46:35.648004Z",
     "start_time": "2018-05-03T10:46:29.238930Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pr = classifier.predict(X_test)\n",
    "\n",
    "Y_pred = []\n",
    "\n",
    "for i in range(len(Y_pr)):\n",
    "    if Y_pr[i][0] >= Y_pr[i][1]:\n",
    "        Y_pred.append('ham')\n",
    "    else:\n",
    "        Y_pred.append('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-03T10:46:35.679708Z",
     "start_time": "2018-05-03T10:46:35.649788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2398   40]\n",
      " [  61  543]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)  \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
